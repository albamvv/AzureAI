# ğŸ’¬ Chat Application with Azure AI Foundry (GPT-4o)

This project demonstrates how to deploy a **GPT-4o model** using **Azure AI Foundry** and create a simple **Python client application** that chats with the deployed model.

---

## ğŸ§© Overview

In this exercise, you will:

1. Deploy the **GPT-4o model** in Azure AI Foundry.  
2. Configure a project and model deployment.  
3. Build a **Python chat client** using the **Azure AI Foundry** and **Azure OpenAI SDKs**.  
4. Interact with your model through a command-line chat interface.  

## Activar entorno

```bash
source labenv/Scripts/activate
```

## âš™ï¸ Prerequisites

Before you start, ensure you have:

- An active **Azure subscription** (`CS-SUB-0417` or equivalent)
- Access to **Azure AI Foundry** and **Azure Portal**
- Basic familiarity with **Python** and **Azure Cloud Shell**
- **Git** and **PowerShell** (if running locally)
- Access to Azure AI Foundry: https://ai.azure.com
- Credentials provided by the instructor
- Permissions to create hubs, projects, and model deployments

##  Set Up the Environment

Create a virtual environment and install dependencies:

```bash
python -m venv labenv
.\labenv\Scripts\activate
pip install azure-identity azure-ai-projects openai
```

## Architecture Notes: Azure AI Foundry + Connected AI Resource

Azure AI Foundry is responsible for orchestration:
- project configuration
- model deployment workflows
- evaluation pipelines
- UI and management experience

The Connected AI Resource (Azure OpenAI) provides:
- model hosting and runtime execution
- inference endpoints and API keys
- quota and throughput limits
- safety filters and enterprise access controls

In this architecture:
- **Foundry** = control plane  
- **Connected AI Resource** = data plane  
Both layers work together to support end-to-end generative AI development.

## Understanding Azure AI Foundry and the Connected AI Resource

Below is a simplified view of how both components work together:

                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚       Azure AI Foundry        â”‚
                 â”‚  â€¢ UI / Workspace             â”‚
                 â”‚  â€¢ Project orchestration      â”‚
                 â”‚  â€¢ Evaluations & pipelines    â”‚
                 â”‚  â€¢ Management & monitoring    â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚ orchestrates
                                 â–¼
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚   Connected AI Resource       â”‚
                 â”‚   (Azure OpenAI backend)      â”‚
                 â”‚  â€¢ Model hosting              â”‚
                 â”‚  â€¢ Inference runtime          â”‚
                 â”‚  â€¢ Quotas & throughput        â”‚
                 â”‚  â€¢ Safety filters & policies  â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Summary:
- Foundry = orchestration layer (control plane)
- Connected AI Resource = execution layer (data plane)






